---
title: "Tema 1. Caracterización de la inteligencia artificial"
subtitle: "Máster en FP de Inteligencia Artificial y Big Data"
---

# Tema 1. Caracterización de la inteligencia artificial

> 1. Definición de Inteligencia Artificial
> 2. Principales Enfoques
> 3. Componentes Fundamentales
> 4. Aplicaciones principales
> 5. **Desafíos éticos y técnicos**
---

## 5. Desafíos éticos y técnicos

Para cerrar el tema se abordarán los principales desafíos técnicos y éticos que enfrenta la Inteligencia Artificial (IA) en su desarrollo y uso. Haremos un enfoque especial en la normativa y recomendaciones de la **Unión Europea (UE)**. El objeto es comprender como estos desafíos influyen en la implementación de sistemas de IA para aportar soluciones tecnológicas basadas en datos y cuáles son las implicaciones éticas y regulatorias que han de tenerse en cuenta.

### Introducción

La **Inteligencia Artificial (IA)** está revolucionando múltiples sectores, pero su crecimiento plantea desafíos éticos y técnicos que deben abordarse para garantizar que su desarrollo sea seguro, justo y beneficioso para la sociedad. Desde cuestiones como la **explicabilidad** de los algoritmos hasta el impacto en el **empleo** y la **privacidad**, estos desafíos son críticos para el futuro de la IA.

La **Unión Europea (UE)** ha sido pionera en establecer marcos regulatorios para una IA confiable, con documentos clave como el **Libro Blanco sobre la IA** y las **Directrices Éticas para una IA Confiable**. Estos documentos subrayan la necesidad de garantizar la **transparencia**, la **seguridad**, la **privacidad** y la **responsabilidad** en el uso de la IA.

> **Pregunta para reflexión inicial**: ¿Por qué crees que es importante regular el uso de la IA de manera ética y técnica? 
>
> **Clave**: Considera los riesgos que implican sistemas de IA no regulados, como la falta de transparencia, la discriminación y los fallos en entornos críticos.

---

### Desafíos técnicos en la IA

#### Explicabilidad y transparencia

##### Definición:
La **explicabilidad** se refiere a la capacidad de un sistema de IA para justificar y explicar cómo toma sus decisiones. Esto es crucial en aplicaciones sensibles como la **medicina** o las **finanzas**, donde un error puede tener graves consecuencias.

> **Ejemplo**: Un caso en el que la explicabilidad es crítica es el uso de **IA en diagnósticos médicos**. Si un algoritmo sugiere un diagnóstico incorrecto, los médicos necesitan entender el proceso que llevó a ese resultado para tomar decisiones informadas.

##### Qué plantea la normativa de la UE:
La **UE**, en sus **Directrices Éticas para una IA Confiable**, subraya que los sistemas de IA deben ser **transparentes** y **explicables**, especialmente en áreas de alto riesgo. Según **Bello y Medina (2020)**, la **falta de transparencia** es uno de los principales obstáculos para la aceptación de la IA por parte del público.

> **Pregunta de reflexión**: ¿Por qué es importante que un sistema de IA sea explicable?
>
> **Clave**: La capacidad de explicar las decisiones de una IA aumenta la **confianza** en los sistemas automatizados, especialmente cuando se trata de **decisiones críticas**.

##### A debate...

> **Pregunta**: ¿Deberían las redes neuronales profundas ser utilizadas en sistemas críticos si no pueden ser explicadas fácilmente?  
>
> **Clave**: La **UE** aboga por que los sistemas críticos sean lo más explicables posible, pero también se reconoce que la **precisión** a menudo requiere comprometer la explicabilidad. Un enfoque balanceado puede ser la solución.

---

#### Sesgos y discriminación en los algoritmos

##### Definición:
Los sistemas de IA pueden heredar y amplificar los **sesgos** de los datos con los que son entrenados. Esto puede llevar a **resultados discriminatorios**, como la **exclusión** de ciertos grupos en procesos de contratación o la **discriminación** en la concesión de créditos.

> ##### Ejemplos
> Un caso real de discriminación algorítmica ocurrió con el **algoritmo de contratación de Amazon**, que tendía a favorecer a candidatos masculinos debido a los sesgos presentes en los datos históricos de contratación, los cuales reflejaban una preferencia por empleados varones.
>
> Otro ejemplo real de sesgo en IA ocurrió con **Optum**, un sistema utilizado en Estados Unidos para asignar atención médica. El algoritmo priorizaba a pacientes basándose en los costos médicos pasados, lo que resultó en una menor asignación de atención a pacientes afroamericanos, que históricamente tenían menos acceso a servicios costosos, perpetuando la desigualdad racial en la atención. ([Más info...](https://okdoctor.es/los-algoritmos-de-ia-influyen-tratamiento-medico/))



##### Normativa de la UE:
La **UE** ha establecido que los sistemas de IA deben ser auditados regularmente para detectar y corregir **sesgos**. En el **Libro Blanco de la IA**, la UE propone establecer marcos para garantizar la **justicia** en la toma de decisiones automatizadas.

> **Pregunta de reflexión**: ¿De dónde provienen los sesgos en la IA?
>
> **Clave**: Los sesgos suelen originarse en los **datos de entrenamiento**, que pueden no ser representativos o estar sesgados por factores históricos o culturales.

##### A debate...
> **Pregunta**: ¿Cómo podemos mitigar los sesgos en los sistemas de IA?  
>
> **Clave**: La **UE** sugiere auditorías de datos y el desarrollo de herramientas para detectar y corregir los sesgos. Además, el uso de **datos más diversos** y el ajuste del diseño del modelo pueden ayudar a mitigar estos efectos.

---

#### Seguridad y robustez

##### Definición:
Los sistemas de IA deben ser **robustos** y capaces de resistir ataques o fallos. En sectores como la **conducción autónoma** o la **salud**, los fallos pueden tener consecuencias fatales.

> **Ejemplo**:
>
> Un ejemplo notable fue el accidente de un coche autónomo de **Uber** en 2018, donde el sistema de IA no pudo reconocer a un peatón en condiciones de baja iluminación. Este caso subraya la necesidad de pruebas rigurosas antes de desplegar sistemas de IA en entornos críticos.
>

##### Normativa de la UE:
En su **Libro Blanco sobre la IA**, la **UE** establece que los sistemas de IA de alto riesgo, como los utilizados en **vehículos autónomos** o **diagnósticos médicos**, deben pasar por pruebas rigurosas y obtener **certificaciones** antes de ser implementados.

> **Pregunta de reflexión**: ¿Qué sucede si un sistema de IA falla en un entorno crítico? 
> **Clave**: Piensa en las consecuencias de un fallo en un **vehículo autónomo** o un **sistema médico**, donde una mala decisión puede tener consecuencias graves.

##### A debate...

> **Pregunta**: ¿Deberían las IA ser probadas de manera más rigurosa antes de su implementación en entornos críticos?  
>
> **Clave**: La UE exige estándares elevados para sistemas de **alto riesgo**, pero también se debe considerar el balance entre la innovación y la seguridad.

---

### Desafíos éticos en la IA

#### Privacidad y protección de datos

##### Definición
La IA a menudo procesa grandes cantidades de **datos personales**, lo que plantea preocupaciones sobre la **privacidad**. El **Reglamento General de Protección de Datos (GDPR)** de la UE establece estrictas normas sobre el manejo de estos datos.

> ##### Ejemplo
> Empresas como **Facebook** han enfrentado sanciones debido a violaciones de la privacidad, como el escándalo de **Cambridge Analytica**, donde se utilizó la IA para analizar datos personales sin consentimiento adecuado. ([Más info...](https://www.youtube.com/watch?v=7831NGClsrM))
>

##### Normativa de la UE:
El **GDPR** establece normas sobre el **consentimiento** y la **anonimización de datos**. La **IA** debe cumplir con estas normativas, y la **UE** sugiere el uso de técnicas como el **aprendizaje federado**, que permite entrenar modelos sin compartir datos privados directamente. En este  caso múltiples dispositivos o servidores colaboran para entrenar un modelo sin compartir los datos locales. Cada dispositivo entrena el modelo localmente y luego envía solo los parámetros actualizados al servidor central, manteniendo así la **privacidad** de los datos.

> **Pregunta de reflexión**: ¿Cuáles son los principales riesgos de privacidad asociados al uso de IA?
>
> **Clave**: Considera cómo la **recolección masiva de datos** puede llevar a violaciones de la privacidad y la posibilidad de **re-identificación** de individuos en datos anonimizados. Un caso real de **re-identificación de usuarios anónimos** ocurrió en 2006, cuando **AOL** publicó un conjunto de datos anonimizados de búsquedas de usuarios. Aunque los datos no incluían nombres, un periodista de **The New York Times** pudo identificar a una persona basándose en las búsquedas específicas que realizaba. Este caso mostró cómo la combinación de datos anónimos con inteligencia artificial y técnicas de cruce de datos puede re-identificar a los usuarios, revelando información personal y comprometiendo la **privacidad**

##### A debate...
> **Pregunta**: ¿Cómo puede la IA cumplir con las normativas de protección de datos sin perder su capacidad de aprendizaje?  
>
> **Clave**: La **UE** fomenta técnicas como la **anonimización** y **encriptación** de datos, así como el uso de **aprendizaje federado** para mitigar estos problemas.

---

#### Impacto en el empleo y desplazamiento laboral

##### Definición
La automatización impulsada por IA puede aumentar la productividad, pero también plantea la posibilidad de **desplazamiento laboral**, especialmente en sectores donde las tareas son repetitivas.

##### Ejemplo:
En **España**, el uso de robots en las fábricas de **SEAT** ha optimizado la producción, pero también ha reemplazado algunos puestos de trabajo manuales. La respuesta de la empresa ha sido implementar programas de **reentrenamiento** para empleados.

##### Normativa de la UE:
La **UE** sugiere la necesidad de **capacitación** y **reciclaje** laboral para preparar a los trabajadores para los nuevos empleos que surgirán en la economía digital, minimizando el impacto del **desplazamiento**.

##### Para reflexionar...

> ¿Qué sectores son más vulnerables al impacto de la IA en términos de pérdida de empleo?
>
> **Clave**: Los sectores que implican **tareas repetitivas** como la **manufactura** y el **transporte** son los más vulnerables, mientras que trabajos creativos o que requieren empatía son menos susceptibles.

##### A debate...
> **Pregunta**: ¿Cómo puede la sociedad equilibrar los beneficios de la IA con el riesgo de pérdida de empleo?  
>
> **Clave**: Considera políticas públicas como la **capacitación** y el **reciclaje** laboral. Algunas propuestas incluyen el **ingreso básico universal** para mitigar el impacto en los trabajadores desplazados.

---

#### **Toma de decisiones autónomas y responsabilidad**

##### Definición:
Cuando los sistemas de IA toman decisiones autónomas surge la pregunta de quién es **responsable** cuando algo sale mal. Esto es especialmente relevante en áreas como la **conducción autónoma**, la **justicia** o las **finanzas**.

> **Ejemplo:** En un accidente de un **vehículo autónomo**, ¿quién es el responsable legal? ¿El fabricante del coche, el desarrollador del software o el propietario del vehículo?

##### Normativa de la UE:
La **UE** ha propuesto marcos legales en los que la **responsabilidad legal** por las decisiones de la IA debe ser **trazable**, es decir, debe poder identificarse claramente quién es el responsable en cada caso.

##### A debate...
> **Pregunta**: ¿Deberían los sistemas de IA tener algún tipo de "responsabilidad" legal o debería recaer siempre sobre los humanos?  
>
> **Clave**: La **UE** sugiere que la responsabilidad debe ser **trazable**, es decir, que siempre se pueda identificar quién fue responsable de las decisiones.

---

### Normativa y Regulaciones de la IA en la Unión Europea

La **Unión Europea (UE)** ha sido pionera en la creación de marcos regulatorios para el desarrollo ético de la **Inteligencia Artificial (IA)**. Ante el crecimiento acelerado de esta tecnología, la UE busca garantizar que la IA se utilice de manera responsable, respetando los derechos fundamentales y promoviendo la confianza en los sistemas automatizados.

#### Contexto histórico y objetivos

En **2018**: La UE publica el **Libro Blanco sobre la IA**, que marca el inicio de la regulación en este ámbito. Se centra en dos objetivos: 

- **Excelencia**: Fomentar la investigación y desarrollo de IA dentro de la UE, para mantener su competitividad tecnológica.
- **Confianza**: Asegurar que la IA respete los derechos fundamentales, promoviendo una IA ética y confiable.

En **2021**: Propuesta del **Reglamento de IA**, que clasifica los sistemas de IA según el riesgo asociado a su uso (alto, medio o bajo). Los sistemas de **alto riesgo** (como los utilizados en **diagnóstico médico** o **conducción autónoma**) deben cumplir requisitos estrictos de **transparencia**, **explicabilidad** y **pruebas exhaustivas** antes de su despliegue.

#### Principios y requisitos

- **Transparencia**: Los usuarios deben poder entender cómo la IA toma decisiones, lo que es crucial en aplicaciones como **finanzas** o **salud**.
- **No discriminación**: Se prohíbe el uso de IA que perpetúe **sesgos** o **discriminación**, como en **algoritmos de contratación**.
- **Protección de datos**: La IA debe cumplir con el **Reglamento General de Protección de Datos (GDPR)**, garantizando la **anonimización** y **seguridad** de la información personal.
- **Responsabilidad**: Los desarrolladores y operadores de IA deben asumir la **responsabilidad legal** de los fallos o consecuencias derivadas del uso de la IA.

#### Casos de uso y restricciones

- **Conducción autónoma**: La UE exige que los vehículos autónomos pasen rigurosas pruebas y certificaciones antes de su implementación.
- **Reconocimiento facial**: El uso de IA para vigilancia masiva está altamente restringido, priorizando los derechos de **privacidad** y **seguridad** de los ciudadanos.

En conjunto, la **UE** busca regular la IA desde una perspectiva equilibrada, fomentando la innovación tecnológica, pero protegiendo los derechos fundamentales.

> **Pregunta para reflexión final**: ¿Deberían otros países seguir el modelo de la UE para regular la IA? 
>
> **Clave**: La UE ha liderado los esfuerzos para regular la IA de manera ética y responsable, pero las normas globales también necesitan adaptarse a contextos locales.

---



La **IA** presenta desafíos técnicos como la **explicabilidad**, la **seguridad** y el **sesgo**, y desafíos éticos como el **impacto en la privacidad** y el **desplazamiento laboral**. Las normativas de la **UE** ofrecen un marco sólido para garantizar que la IA sea confiable y beneficiosa para la sociedad.

##### A debate...

> **¿Es suficiente el marco regulatorio de la UE para abordar los desafíos éticos de la IA?**
>
> **Puntos a debatir**: La normativa de la UE es una de las más avanzadas en cuanto a **protección de derechos fundamentales** y **transparencia** en el uso de la IA. Sin embargo, ¿es suficiente para cubrir las nuevas aplicaciones emergentes? ¿Es capaz de adaptarse rápidamente a los cambios tecnológicos?
>
> **Aspectos a considerar**: La rapidez con la que se desarrollan las nuevas tecnologías, los posibles vacíos legales y las limitaciones que puede imponer la regulación a la innovación.



> **¿El enfoque de clasificación de riesgos de la IA propuesto por la UE es práctico en todos los sectores?**
>
> **Puntos a debatir**: El **Reglamento de IA** clasifica los sistemas según su riesgo (alto, medio o bajo) y aplica diferentes niveles de regulación. ¿Es adecuado aplicar esta clasificación en sectores como la salud, la conducción autónoma o la vigilancia, donde los riesgos pueden evolucionar?
>
> **Aspectos a considerar**: La flexibilidad de la clasificación y su aplicabilidad en sectores donde los riesgos de la IA pueden cambiar rápidamente.



> **¿Cómo debería la UE equilibrar la innovación tecnológica con la protección de los derechos fundamentales?**
>
> **Puntos a debatir**: La **Unión Europea** promueve la **excelencia** y la **confianza** en la IA. Sin embargo, la regulación estricta podría limitar la innovación. ¿Cómo debería la UE equilibrar la necesidad de proteger los derechos y al mismo tiempo fomentar el avance tecnológico?
>
> **Aspectos a considerar**: Las implicaciones económicas, el papel de los desarrolladores de IA, y el impacto que puede tener una normativa estricta en la competitividad global de Europa en tecnologías de IA.

---





